{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree \n",
    "## best score 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/our_train.csv')\n",
    "test = pd.read_csv('Data/our_test.csv')\n",
    "val = pd.read_csv('Data/our_val.csv')\n",
    "df = pd.read_csv('Data/train.csv')\n",
    "\n",
    "X_train = train.drop('NObeyesdad', axis=1)\n",
    "y_train = train['NObeyesdad']\n",
    "X_test = test.drop('NObeyesdad', axis=1)\n",
    "y_test = test['NObeyesdad']\n",
    "X_val = val.drop('NObeyesdad', axis=1)\n",
    "y_val = val['NObeyesdad']\n",
    "\n",
    "CAEC_dict = {'no': 0, 'Sometimes': 0.33, 'Frequently': 0.66, 'Always': 1 }\n",
    "CALC_dict = {'no': 0, 'Sometimes': 0.5, 'Frequently': 1}\n",
    "X_train['CAEC'] = X_train['CAEC'].map(CAEC_dict)\n",
    "X_train['CALC'] = X_train['CALC'].map(CALC_dict)\n",
    "X_test['CAEC'] = X_test['CAEC'].map(CAEC_dict)\n",
    "X_test['CALC'] = X_test['CALC'].map(CALC_dict)\n",
    "X_val['CAEC'] = X_val['CAEC'].map(CAEC_dict)\n",
    "X_val['CALC'] = X_val['CALC'].map(CALC_dict)\n",
    "cat_cols2 = ['Gender', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC', 'MTRANS']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols2:\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_test[col] = le.fit_transform(X_test[col])\n",
    "    X_val[col] = le.fit_transform(X_val[col])\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "y_val = le.fit_transform(y_val)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       525\n",
      "           1       0.79      0.80      0.79       624\n",
      "           2       0.81      0.77      0.79       604\n",
      "           3       0.95      0.95      0.95       714\n",
      "           4       0.98      1.00      0.99       837\n",
      "           5       0.67      0.67      0.67       532\n",
      "           6       0.68      0.71      0.70       523\n",
      "\n",
      "    accuracy                           0.84      4359\n",
      "   macro avg       0.83      0.83      0.83      4359\n",
      "weighted avg       0.84      0.84      0.84      4359\n",
      "\n",
      "Confusion matrix:\n",
      " [[460  56   2   0   0   5   2]\n",
      " [ 45 502   1   0   0  63  13]\n",
      " [  1   5 465  29   7  25  72]\n",
      " [  0   0  24 681   5   0   4]\n",
      " [  1   0   3   0 833   0   0]\n",
      " [  2  62  28   0   1 359  80]\n",
      " [  2  14  49   5   0  83 370]]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred1 = dt.predict(X_val)\n",
    "class_report1 = classification_report(y_val, y_pred1)\n",
    "print(\"Classification report:\\n\", class_report1)\n",
    "\n",
    "conf_matrix1 = confusion_matrix(y_val, y_pred1)\n",
    "print(\"Confusion matrix:\\n\", conf_matrix1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score: 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 450 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gaspar\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "450 fits failed out of a total of 1350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gaspar\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Gaspar\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\Gaspar\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Gaspar\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.34473504 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504\n",
      " 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504\n",
      " 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504\n",
      " 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504\n",
      " 0.34473504 0.66173384 0.66173384 0.66173384 0.66173384 0.66173384\n",
      " 0.75994514 0.75994514 0.75994514 0.75994514 0.75994514 0.83537515\n",
      " 0.83537515 0.83537515 0.83461804 0.83399865 0.835857   0.835857\n",
      " 0.83565048 0.83441157 0.83392982 0.835857   0.835857   0.83565048\n",
      " 0.83441157 0.83392982 0.66173384 0.66173384 0.66173384 0.66173384\n",
      " 0.66173384 0.75994514 0.75994514 0.75994514 0.75994514 0.75994514\n",
      " 0.84735043 0.84735043 0.84735043 0.84638684 0.84101894 0.87295278\n",
      " 0.87295278 0.86909866 0.85698535 0.84095008 0.87556812 0.87556812\n",
      " 0.866621   0.85677888 0.84095008 0.66173384 0.66173384 0.66173384\n",
      " 0.66173384 0.66173384 0.75994514 0.75994514 0.75994514 0.75994514\n",
      " 0.75994514 0.84735043 0.84735043 0.84735043 0.84638684 0.84101894\n",
      " 0.87295278 0.87295278 0.86909866 0.85677887 0.84067477 0.87515515\n",
      " 0.87522397 0.86586385 0.85664118 0.84067477 0.66173384 0.66173384\n",
      " 0.66173384 0.66173384 0.66173384 0.75994514 0.75994514 0.75994514\n",
      " 0.75994514 0.75994514 0.84735043 0.84735043 0.84735043 0.84638684\n",
      " 0.84101894 0.87295278 0.87295278 0.86909866 0.85677887 0.84067477\n",
      " 0.87515515 0.87522397 0.86586385 0.85664118 0.84067477 0.66173384\n",
      " 0.66173384 0.66173384 0.66173384 0.66173384 0.75994514 0.75994514\n",
      " 0.75994514 0.75994514 0.75994514 0.84735043 0.84735043 0.84735043\n",
      " 0.84638684 0.84101894 0.87295278 0.87295278 0.86909866 0.85677887\n",
      " 0.84067477 0.87515515 0.87522397 0.86586385 0.85664118 0.84067477\n",
      " 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504\n",
      " 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504\n",
      " 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504\n",
      " 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504 0.34473504\n",
      " 0.34473504 0.64618037 0.64618037 0.64618037 0.64618037 0.64618037\n",
      " 0.76538232 0.76538232 0.76538232 0.76538232 0.76538232 0.82608394\n",
      " 0.82608394 0.82608394 0.82608394 0.81397148 0.82573985 0.82573985\n",
      " 0.82642808 0.82608394 0.81397148 0.82573985 0.82573985 0.82642808\n",
      " 0.82608394 0.81397148 0.64618037 0.64618037 0.64618037 0.64618037\n",
      " 0.64618037 0.76538232 0.76538232 0.76538232 0.76538232 0.76538232\n",
      " 0.84280835 0.84280835 0.84280835 0.84280835 0.83682099 0.86847922\n",
      " 0.86847922 0.8675157  0.86132173 0.8370274  0.87192057 0.87192057\n",
      " 0.86868558 0.86132173 0.8370274  0.64618037 0.64618037 0.64618037\n",
      " 0.64618037 0.64618037 0.76538232 0.76538232 0.76538232 0.76538232\n",
      " 0.76538232 0.84280835 0.84280835 0.84280835 0.84280835 0.83682099\n",
      " 0.86847922 0.86847922 0.8675157  0.86125291 0.8370274  0.87240231\n",
      " 0.87240231 0.8687544  0.86125291 0.8370274  0.64618037 0.64618037\n",
      " 0.64618037 0.64618037 0.64618037 0.76538232 0.76538232 0.76538232\n",
      " 0.76538232 0.76538232 0.84280835 0.84280835 0.84280835 0.84280835\n",
      " 0.83682099 0.86847922 0.86847922 0.8675157  0.86125291 0.8370274\n",
      " 0.87240231 0.87240231 0.8687544  0.86125291 0.8370274  0.64618037\n",
      " 0.64618037 0.64618037 0.64618037 0.64618037 0.76538232 0.76538232\n",
      " 0.76538232 0.76538232 0.76538232 0.84280835 0.84280835 0.84280835\n",
      " 0.84280835 0.83682099 0.86847922 0.86847922 0.8675157  0.86125291\n",
      " 0.8370274  0.87240231 0.87240231 0.8687544  0.86125291 0.8370274\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'criterion': 'gini', 'max_depth': 10, 'max_leaf_nodes': 100, 'min_samples_split': 5}\n",
      "Best score:  0.8755681211397643\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid = dict(criterion=['gini', 'entropy', 'log_loss'],\n",
    "            max_depth=[1, 5, 10, 50, 75, 100],\n",
    "            min_samples_split=[5, 10, 100, 250, 500],\n",
    "            max_leaf_nodes=[5, 10, 20, 50, 100])\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dt, param_grid = param_grid, scoring=\"accuracy\", n_jobs=-1, cv=3, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters: \", best_params)\n",
    "print(\"Best score: \", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters:  {'criterion': 'gini', 'max_depth': 10, 'max_leaf_nodes': 100, 'min_samples_split': 5}\n",
    "Best score:  0.8755681211397643"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       525\n",
      "           1       0.82      0.83      0.83       624\n",
      "           2       0.85      0.84      0.85       604\n",
      "           3       0.96      0.96      0.96       714\n",
      "           4       0.99      1.00      1.00       837\n",
      "           5       0.72      0.74      0.73       532\n",
      "           6       0.76      0.76      0.76       523\n",
      "\n",
      "    accuracy                           0.87      4359\n",
      "   macro avg       0.86      0.86      0.86      4359\n",
      "weighted avg       0.88      0.87      0.88      4359\n",
      "\n",
      "Confusion matrix:\n",
      " [[478  43   0   0   0   3   1]\n",
      " [ 33 518   0   0   0  68   5]\n",
      " [  2   2 505  23   3  20  49]\n",
      " [  0   0  23 688   2   0   1]\n",
      " [  1   0   1   1 834   0   0]\n",
      " [  0  55  15   0   0 396  66]\n",
      " [  0  11  47   4   0  66 395]]\n"
     ]
    }
   ],
   "source": [
    "best = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_split=5, max_leaf_nodes=100, random_state=42)\n",
    "best.fit(X_train, y_train)\n",
    "y_pred2 = best.predict(X_val)\n",
    "class_report2 = classification_report(y_val, y_pred2)\n",
    "print(\"Classification report:\\n\", class_report2)\n",
    "conf_matrix2 = confusion_matrix(y_val, y_pred2)\n",
    "print(\"Confusion matrix:\\n\", conf_matrix2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
